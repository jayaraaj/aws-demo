[
{
	"uri": "https://aws-hugo.web.app/45_build_deploy_assurance/1_introduction.html",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Objective: To check the readiness of the build for testing and preparing the environment for subsequent test executions In this stage, developers and testers focus on a set of tests adequate to ensure critical functionalities work as required in the build and these tests are also known as build verification testing, confidence testing (or) build acceptance testing. PIPELINE OVERVIEW In this module, you will explore the Post Build Quality Assurance stage of the overall testing pipeline for DevOps. This stage is key in confirming the deployed build is stable (or) not and the purpose of the assurance carried out here is to confirm if the QA team can proceed with further testing.\nPost-Build Quality Assurance flow:\nThis module consists of two stages viz. Code Deployment and Smoke Testing.\n  Deployment of Application: Leverage AWS System Manager for deploying back-end and front-end components of the application under test. This is achieved via SSM Document which executes remote deployment run commands on the associated EC2 instances.\n  Smoke Testing: Balanced mix of API and UI based test automation in the form of Smoke (or) Build Verification Test is implemented using the open source tools like Selenium and RestAssured with BDD Cucumber Framework. The test scripts will be executed using AWS CodeBuild and the results will be saved in the directory awswrkshp_build_deploy_assurance_smoke/target/extent-reports in the target s3 bucket.\n  "
},
{
	"uri": "https://aws-hugo.web.app/46_functional_assurance/1_introduction.html",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Objective: To validate application\u0026rsquo;s functional behavior such as business process, user workflows \u0026amp; regression impact against the pre-defined outcomes Functional behaviors are “what” the system should do. Functional testing evaluates if functions perform as expected. Functional requirements may be described and documented in business requirements specifications, epics, user stories, use cases, (or) functional specifications, or they may be undocumented.\nThese tests should be performed at all test levels, though the focus is different at each level. For our particular use case, we will focus on the following\n UI focuses on validating business process through screens and objects API focuses on back-end services leveraged by front-end elements and objects Mobile refers to an RWD (Responsive Web Design) based interfaces  PIPELINE OVERVIEW This module will walk you through the assurance of your application functionalities. You will learn how to execute UI-based tests, responsive web design (RWD)-based tests and API tests with an open source tool stack.\nThe Functional Assurance pipeline consists of two stages viz. source and build.\nWith every code change committed to the repository, the pipeline will trigger all the three tests in a parallel i.e. UI based testing, RWD testing and API testing tests. Various dependencies and commands required for respective tests are defined in the buildspec.yml file in the source code repository.\nAutomation for UI on desktop and mobile with RWD tests is implemented using open source tools – Selenium, Cucumber and Maven following Page Factory Pattern:\n  UI Automation: Ten test cases will be executed using AWS CodeBuild and the results will be saved in the directory - awswrkshp_functional_assurance_ui/target/extent-reports in the target s3 bucket.\n  RWD Automation: Five test cases will be executed on mobile compatible application rendered on Chrome web browser and results will be saved in the directory - awswrkshp_functional_assurance_ui_rwd/target/extent-reports in the target s3 bucket.\n  API Tests: API based test automation is implemented using the open source tools like Rest-Assured, Maven and Cucumber. Ten test cases will be executed on the AWS CodeBuild and the results will be saved in the directory - awswrkshp_functional_assurance_api /target/extent-reports in the target s3 bucket.\n  "
},
{
	"uri": "https://aws-hugo.web.app/47_experience_assurance/1_introduction.html",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Objective: To validate application’s non-functional behavior such as performance, accessibility \u0026amp; security meet acceptable / pre-defined benchmarks Non-functional behaviors are “How” the system should perform its functions. In today’s digital age, it’s not just about if an application works, but more importantly, how it works. Testing an application to validate its performance, security and accessibility is commonly known as Non-functional Testing (NFT).\nShift left with NFT, allows developers / testers to leverage scaled-down environments for non-functional testing at a component level as and when, they are developed. The re-use of open source frameworks and functional automation scripts to perform early NFT, reduces the overall vulnerabilities in later stages. Additionally, Application Performance Management (APM) for end-to-end monitoring, alert mechanism and virtualization techniques, ensure continuous Non-Functional Testing.\nNon-Functional Testing in DevOps is integrated across the lifecycle, here are few typical use cases:\n During build phase, it includes code-quality analysis, code profiling, single user performance validation etc. During environment setup, it covers automatic spin-off, off load generation environment, automatic environment configuration and test execution. During functional testing, it leverages automation scripts for client-side performance and accessibility assessments.  PIPELINE OVERVIEW In this module, you will explore how experience is assured with non-functional testing. In digital, customer experience is critical for success and non-functional aspects play a significant role in an application’s functionality. You will see how an application’s performance, security and accessibility are validated in continuous pipeline with an open source tool stack.\nThe Experience Assurance pipeline consists of two stages viz. source and build.\nWith every code change committed to the repository, all three tests will be triggered in a sequence. Various dependencies and commands required for these tests are defined in the buildspec.yml file in the source code repository.\nPerformance Tests are executed with the open-source tool Jmeter (version 5.1.1). The tests will run with five concurrent users and results will be saved in the directory “performance_test_results” in the target s3 bucket.\nPerformance Tests source files:\n AWSWrksp_NFTPerformance_Scenario.jmx – jmeter scenario file with required transactions. data_*.csv files – input data files to be used inside jmeter scenario during runtime (such as credentials, sample credit cards, product names). .py files – a set of python files to send data to result dashboard and to pass / fail the build run based on few conditions such as response time SLA and transaction failures.  Security Tests are triggered via the open-source tool owasp ZAP. These tests will perform a passive baseline security scan with predefined rules against the given URL and save the results under “security_test_results” in the target s3 bucket.\nSecurity Tests source files:\n gen.conf – List of passive scan rules to be used by ZAP proxy during runtime. .py files - a set of python files to send data to result dashboard and to pass / fail the build run based on rule failures (as defined in gen.conf file).  Accessibility Tests are run using Selenium and AXE tool to analyze the application’s response against accessibility guidelines. Here, accessibility checks are done on steps executed by Selenium scripts (for each page that is rendered) and results are displayed under “accessibility_test_results” in the target s3 bucket.\nAccessibility Tests source files:\n Selenium project files – with a simple scenario and AXE tool dependencies in pom.xml to validate the accessibility in each step.  "
},
{
	"uri": "https://aws-hugo.web.app/48_end_to_end_testing_assurance/1_introduction.html",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Objective: To execute the continuous testing pipeline with all the pre-defined quality gates In prior modules, you have seen how tests are required to verify all facets of the application viz. – functional, performance, security, accessibility etc. You have also seen the need for quality assurance for not just the UI, but also at a component level viz. – code, build, deployment, data \u0026amp; interfacing services. You have seen a few examples of application defects and test incidents that can occur during a test pipeline execution and understood how to fix them.\nPIPELINE OVERVIEW If you have commenced the workshop from this module, you will encounter 3 failures while executing the end-to-end pipeline. Please refer ‘Build and Execute’ and ‘Debug \u0026amp; Fix’ sections of Module 1, Module 3 and Module 4 to understand these failures and how to fix them.\n In this fifth and final module, you will execute all the same tests executed as the part of previous modules, but in a continuous testing pipeline from code commit to final reports. Additionally, in this module you will also read about new-age QA practices like, AI driven QA that are increasingly becoming critical for modern-day testing in DevOps.\nEnd-to-end Quality Assurance Code Pipeline consists of the following stages and components:\n•\tSource Stage – contains source code for all the subsequent stages i.e. application source code for front-end and back-end, functional test code for Smoke, API, UI and RWD testing types and code for experience assurance testing types, namely – performance, security and accessibility.\n•\tPre-Build Quality Check – induces static code quality measures on both the front-end and back-end components of application under test for continuous inspection of code quality to detect bugs, code smells and security vulnerabilities.\n•\tUnit Test – pipeline further has a robust suite of unit tests, complimented by code coverage techniques to give actionable guidance and identify any critical slips.\n•\tBuild – if no issues are detected in the pipeline at unit testing stage, process continues further by building and packaging the application.\n•\tDeploy to Test – on successful build, AWS Systems Manager is leveraged to deploy back-end and front-end components of the application to EC2 instance.\n•\tPost Build Quality Check – runs smoke test to qualify the build for further stages of testing.\n•\tFunctional Assurance - evaluates functional behaviours i.e. “what” the system should do (or) if the application / system functions perform as expected by executing a comprehensive set of APIs, UI and RWD tests as parallel CodeBuild jobs.\n•\tExperience Assurance - evaluates non-functional behaviours i.e. “How” the system should perform its functions by executing performance, security and accessibility tests as sequential CodeBuild jobs.\n"
},
{
	"uri": "https://aws-hugo.web.app/",
	"title": "Test Automation in DevOps",
	"tags": [],
	"description": "",
	"content": "Test Automation in DevOps Digital transformation requires speed and efficiency across the DevOps lifecycle. At the same time, this enhanced speed and efficiency should not come at the cost of quality and overall customer experience. Based on our experience, we believe that the best way to achieve these goals is through the introduction of continuous testing in DevOps.\n"
},
{
	"uri": "https://aws-hugo.web.app/60_clean_up/1_cleanup.html",
	"title": "Clean-up Activities",
	"tags": [],
	"description": "",
	"content": "When you are ready, just follow these last two steps to clean up the resources that were setup just for this workshop.\nIn order to prevent charges to your account, we recommend cleaning up the infrastructure that was created. If you plan to keep things running, so you can examine the workshop a bit more, then please remember to do the clean-up when you are done. It is very easy to leave things running in an AWS account, forget about it, and then accrue charges.\nCopy, paste and execute the following commands into Cloud9’s terminal in sequence to commence the clean-up activity.\nwget https://aws-wrkshp-artifacts.s3-eu-west-1.amazonaws.com/awsworkshop_infrastructure_artefacts/awsworskhop_cleanup_environment.sh chmod +x awsworskhop_cleanup_environment.sh ./awsworskhop_cleanup_environment.sh  This complete step takes approximately 5 minutes and if successful, you should see the following relevant messages for each command:\n In the AWS console, go to CloudFormation and verify that none of the stacks are listed in CloudFormation and then you are done.\nFinally, close the Cloud9 window and manually delete your Cloud9 environment. Please follow the below steps:\n In the AWS console, navigate to Cloud9. Select your Cloud9 Environment Click on Delete Type the phrase \u0026ldquo;Delete\u0026rdquo; into the field below, then press Delete?.  "
},
{
	"uri": "https://aws-hugo.web.app/10_prerequisites/1_aws_account.html",
	"title": "Create an AWS account",
	"tags": [],
	"description": "",
	"content": " Your account must have the ability to create new IAM roles and scope other IAM permissions.\n If you already have an AWS account, and have IAM Administrator access, you can skip this page.\n   If you do not already have an AWS account with Administrator access: create one now\n  Once you have an AWS account, ensure you are following the remaining workshop steps as an IAM user with administrator access to the AWS account: Create a new IAM user to use for the workshop\n  Enter the user details:   Attach the AdministratorAccess IAM Policy:   Click to create the new user:   Take note of the login URL and save:   "
},
{
	"uri": "https://aws-hugo.web.app/30_pre_build_quality_assurance/1_introduction.html",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Objective: To assure quality of the code committed before the build creation In software development, build refers to the process of converting files and other assets under developer\u0026rsquo;s responsibility into a software product in its final (or) consumable form. These activities cover: Compile source files -\u0026gt; Package compiled files into compressed formats (like jar, zip) -\u0026gt; Produce installer’s -\u0026gt; Create (or) update Database schema (or) data\nIn DevOps, tests are designed and automated even before the code is written. To deliver quality at speed, developers execute a series of automated test cases prior to committing the code to a repository. This helps to identify any issues or vulnerabilities much earlier in the lifecycle, thereby engineering quality into the code as it progresses.\nPIPELINE OVERVIEW In this section, you will learn how to execute static code analysis, unit testing, sanity UI testing and measure code coverage with an open source tool stack. The Pre-Build Quality Assurance CodePipeline consists of the following stages and components:\n Source Stage monitors changes to below source code repository for any new commits:  FrontEndReactApp – Code for front-end application BackEndSpringBootApp – Code for back-end micro services.    Every code Commit will trigger the CodeBuild job.\n Pre-Build Quality Check uses SonarQube for continuous inspection of code quality and perform automatic reviews with static code analysis to detect bugs, code smells and security vulnerabilities for both front-end and back-end code. Separate CodeBuild jobs i.e. ReactAppSonarCheck and SpringBootSonarCheck are created to induce static code quality measures on both the components of application under test.\n  Unit Test is a series of tests configured as CodeBuild actions i.e. ReactAppUnitTest and SpringBootUnitTest that validate all parts of the application under test. In case of issues, this phase of the CodePipeline process is ended with a failure status. If no issues are detected, the pipeline proceeds to the build stage. Enzyme and Jest libraries are used for unit testing of the front-end. Similarly, Junit and Mockito is used for the back-end micro services.\n  This stage is also complimented with code coverage tools such as Jacoco for back-end and Jest for front-end code for actionable guidance and identifying critical slips. You will be able to see the status of these tests on the reporting dashboard and the code coverage on SONARQube dashboard.\n Build commences with the creation of Docker image for front-end applications. When a new Docker image is successfully built, it is pushed to Amazon ECR.\n  Deploy to Fargate deploys the image created in the build stage to AWS Fargate cluster, which spins up the following two containers -. frontendapplication and virtualizedbackend with the latest image. At this stage, front-end application is pointing to a virtualized back-end so that tests can be executed without back-end dependencies - one of the key advantages of virtualization.\n  A portion of developers’ UI tests are also executed using playwright and Jest at this stage to ensure the front-end image is properly built and running along with virtualized back-end.\nECS and the Application Load Balancer will continuously monitor the health of the container and the application and will always make required adjustments to keep optimal healthy container tasks running.\nAdditionally, Practitioners can access Cognizant Thought Leadership on Containers for DevOps, by referring the comprehensive whitepaper by our technology experts titled - “Using Containers to More Effectively Manage DevOps Continuous Integration”. You will find the link to the whitepaper in the Register with Cognizant page - https://www.cognizant.com/application-modernization.\n "
},
{
	"uri": "https://aws-hugo.web.app/50_conclusion/1_recap.html",
	"title": "Recap",
	"tags": [],
	"description": "",
	"content": "Congratulations Well Done! With your help we have successfully demonstrated to Mythical Mysfits team, how to orchestrate their Testing in DevOps and enable earlier defect detection and higher-quality deployments.\nYou have successfully completed the “Test Automation in DevOps” workshop, embracing quality assurance across the lifecycle.\nWe have accomplished In this workshop, we have built, fixed and executed the Continuous Testing pipeline. Along with this hands-on implementation, you now also have a high-level understanding on testing in DevOps, including various testing stages, their objectives, challenges, enablers and some industry best practices.\nAs committed in the \u0026lsquo;In-Store for Practitioners\u0026rsquo; section, we have discussed the answers to the following questions in this workshop :\n Why QA is integral to a successful DevOps implementation How testing for DevOps is different than traditional testing What various types and stages of testing are essential for end-to-end quality assurance How to build and execute the continuous testing pipeline What are the various tooling alternatives, enablers and best practices in testing for DevOps How to integrate open-source tools based automation suits with the pipeline How to fix typical issues and fix your continuous testing pipeline  "
},
{
	"uri": "https://aws-hugo.web.app/30_pre_build_quality_assurance/2_build_execute.html",
	"title": "Build &amp; Execute",
	"tags": [],
	"description": "",
	"content": "PIPELINE CREATION AND EXECUTION To deploy the pipeline, run the following commands in Cloud9’s terminal:\naws cloudformation create-stack --stack-name PreBuildQA --template-url https://aws-wrkshp-artifacts.s3-eu-west-1.amazonaws.com/awsworkshop_infrastructure_artefacts/awsworkshop_prebuild_qa.json --capabilities CAPABILITY_NAMED_IAM Go to the CloudFormation console and check the status of your pipeline stack creation, named \u0026lsquo;PreBuildQA\u0026rsquo;. It should state - “CREATE_IN_PROGRESS”\r.\nThis step takes approximately ~1minute and if successful, you can see the status of STACK - ‘PreBuildQA’ as “CREATE_COMPLETE”, as shown in the screenshot below:  Please click on your stack name. Under Outputs tabs, details of the key services created will reflect. Refer the screenshot as shown below:\nAll the necessary details are also added in AWS Secrets Manager as Secrets, so that these values can be utilized throughout the various components that we will build as the part of this workshop.\nAt this point, you should also have an automatically triggered, fully functioning Pre-Build-QA CodePipeline.\nIf you head over to CodePipeline in the AWS console and click on the pipeline that begins with the name workshop-codepipeline_prebuildqualitycheck, you should see the screen as shown below:\nYou will notice that the Pipeline fails at the UnitTest stage - ReactAppUnitTest and thus the subsequent steps (Build and Deploy to Fargate) are not executed.\nLet us debug and fix this issue to re-execute the pipeline and then see the impact on subsequent stages.\n"
},
{
	"uri": "https://aws-hugo.web.app/45_build_deploy_assurance/2_build_execute.html",
	"title": "Build &amp; Execute",
	"tags": [],
	"description": "",
	"content": "PIPELINE CREATION AND EXECUTION To deploy the pipeline, run the following commands in Cloud9’s terminal:\naws cloudformation create-stack --stack-name PostBuildQA --template-url https://aws-wrkshp-artifacts.s3-eu-west-1.amazonaws.com/awsworkshop_infrastructure_artefacts/awsworkshop_postbuild_qa.json --capabilities CAPABILITY_NAMED_IAM Go to the CloudFormation console and check the status of your pipeline stack creation named \u0026lsquo;PostBuildQA\u0026rsquo;. It should state - “CREATE_IN_PROGRESS”\r.\nThis step takes approximately 1 minute and if successful, you can see the status of STACK - ‘PostBuildQA’ as “CREATE_COMPLETE”, as shown in the screenshot below:\n At this point, you should have automatically triggered, a fully functioning Post-Build-QA CodePipeline.\nIf you head over to CodePipeline in the AWS console and click on the pipeline that begins with the name workshop_codepipeline_PostBuildQA, you should see the screen as shown below:\nOn successful execution of the pipeline you should have the working instance of your Application in the test environment. To access the application, replace the value of key ‘AppServer_PublicIP’ which you have noted from the secrets (Secrets Manager) section, of the Getting Started section in below URL\n Application Under Test URL is - http://\u0026lt; AppServer_PublicIP \u0026gt;:3000  This application (refer the screenshot as shown below) has now been deployed, smoke tested and ready for functional assurance.\n"
},
{
	"uri": "https://aws-hugo.web.app/46_functional_assurance/2_build_execute.html",
	"title": "Build &amp; Execute",
	"tags": [],
	"description": "",
	"content": "PIPELINE CREATION AND EXECUTION Please complete the Module 2: Post-Build QA before commencing with this module. This will ensure you have deployed the build on the server successfully before executing the Functional test suits during this module.\n Execute the cloud formation template from Cloud9 to automatically create the Functional Assurance pipeline.\naws cloudformation create-stack --stack-name FunctionalAssurance --template-url https://aws-wrkshp-artifacts.s3-eu-west-1.amazonaws.com/awsworkshop_infrastructure_artefacts/awsworkshop_functional_assurance.json --capabilities CAPABILITY_NAMED_IAM Go to the CloudFormation console and check the status of your pipeline stack creation named \u0026lsquo;FunctionalAssurance\u0026rsquo;. It should state - “CREATE_IN_PROGRESS”\rThis step takes approximately 1 minute and if successful, you can see the status of STACK - \u0026lsquo;FunctionalAssurance\u0026rsquo; as\n“CREATE_COMPLETE”, as shown in the screenshot below:\n Note - On successful creation of the pipeline, the CFN will auto trigger the execution. You can now view the execution progress by navigating to Pipeline and selecting - codepipeline_Functional_Assurance.\nYou will notice the three tests are being executed in parallel.\nSoon, you will see the Pipeline fails for the UI and RWD tests.\nNavigate to the Build -\u0026gt; UI_Test -\u0026gt; Details\nLet us debug to re-execute the pipeline.\nAdditionally, Practitioners can access Cognizant Thought Leadership on CI/CD for Web Services Testing, by referring the insightful whitepaper by our technology experts titled - “Continuous Integration and Continuous Delivery to Facilitate Web Service Testing”. You will find the link to the whitepaper in the Register with Cognizant page -https://www.cognizant.com/application-modernization.\n "
},
{
	"uri": "https://aws-hugo.web.app/47_experience_assurance/2_build_execute.html",
	"title": "Build &amp; Execute",
	"tags": [],
	"description": "",
	"content": "PIPELINE CREATION AND EXECUTION Please complete the Module 2: Post-Build QA before commencing with this module. This will ensure you have deployed the build on the server successfully before executing the Experience test suits during this module.\n Execute the cloud formation template from Cloud9 to automatically create the Experience Assurance pipeline.\naws cloudformation create-stack --stack-name ExperienceAssurance --template-url https://aws-wrkshp-artifacts.s3-eu-west-1.amazonaws.com/awsworkshop_infrastructure_artefacts/awsworkshop_experience_assurance.json --capabilities CAPABILITY_NAMED_IAM Go to the CloudFormation console and check the status of your pipeline stack creation named ‘ExperienceAssurance’. It should state - “CREATE_IN_PROGRESS”\r.\nThis step takes approximately 1 minute and if successful, you can see the status of STACK - ‘ExperienceAssurance’ as “CREATE_COMPLETE”, as shown in the screenshot below\n Go to the CloudFormation console and check the status of your pipeline stack creation named ‘ExperienceAssurance’. It should state - “CREATE_IN_PROGRESS”\r.\nNote: On successful creation of the pipeline, the CFN will also auto trigger the execution. You can now view the execution progress by navigating to CodePipeline and selecting codepipeline_experience_assurance\nYou will notice the pipeline fails at security testing and thus the subsequent step for accessibility test is not executed.\nLet us fix this issue to re-execute the pipeline and check the overall non-functional impact of the code change committed.\nAdditionally, Practitioners can access Cognizant Thought Leadership on Performance Testing for SaaS-based Applications, please review the insightful blog by our technology expert on “Performance Assurance for SaaS-based Applications”.\n "
},
{
	"uri": "https://aws-hugo.web.app/48_end_to_end_testing_assurance/2_build_execute.html",
	"title": "Build &amp; Execute",
	"tags": [],
	"description": "",
	"content": "PIPELINE CREATION AND EXECUTION To deploy the pipeline, run the following commands in Cloud9’s terminal\naws cloudformation create-stack --stack-name E2EAssurance --template-url https://aws-wrkshp-artifacts.s3-eu-west-1.amazonaws.com/awsworkshop_infrastructure_artefacts/awsworkshop_e2e_assurance.json --capabilities CAPABILITY_NAMED_IAM Go to the CloudFormation console and check the status of your pipeline stack creation named \u0026lsquo;E2EAssurance\u0026rsquo;. It should state - “CREATE_IN_PROGRESS”\rThis step takes approximately 1 minute and if successful, you can see the status of STACK - ‘E2EAssurance’ as “CREATE_COMPLETE”as shown in the screenshot below:\n At this point, you should have automatically triggered a fully functioning End-to-End-QA CodePipeline.\nHead over CodePipeline the AWS console and click on the pipeline that begins with the name workshop- workshopcodepipelineE2E, you will see the screen as shown below: Click on the pipeline and you will see the complete End-to-End (E2E) Assurance Pipeline.\nAs a result, of the complete pipeline being executed successfully, you should have the working instance of you Application under Test deployed in EC2 instance.\nTo access the application, replace the value of key ‘AppServer_PublicIP ‘ which you have noted from the secrets (Secrets Manager) section of Getting Started section in below URL:\n Application Under Test URL is - http://\u0026lt; AppServer_PublicIP \u0026gt;:3000  "
},
{
	"uri": "https://aws-hugo.web.app/10_prerequisites/2_create_a_cognizant_account_to_access_workshop_content.html",
	"title": "Register with Cognizant",
	"tags": [],
	"description": "",
	"content": " In addition to the workshop itself, we are pleased to offer you several thought leadership and research pieces about testing from a few experienced testing experts at Cognizant. We ask that you kindly register yourself at: https://www.cognizant.com/application-modernization\n Steps for Registration  Click on the Link Provide following input in the given form:   First and Last Name Update Company Update Email ID Update Industry Update Job Title  Click on Register Button  Estimated time required to complete registration: 2 minutes.\n "
},
{
	"uri": "https://aws-hugo.web.app/30_pre_build_quality_assurance/3_debug_fix.html",
	"title": "Debug &amp; Fix",
	"tags": [],
	"description": "",
	"content": "DEBUGGING AND RE-EXECUTION To debug the issue, from the AWSCodeBuild you can go to CodeBuild section \u0026ndash;\u0026gt; Report History and click on the latest failed link under Test Reports History.\nYou can then view the below report. Click on the failed test case to see the reason for failure.\nAlternatively, please switch to your Reporting Dashboard and go to the section UnitTest to view the summary of this stage. Click on the component to view detailed test report to spot where the test failed. (This will link you to the above report)\nLet’s understand the nature of the failure.\nWhat is the failure?\nOne of the unit tests named ‘Register - Last name should be present’ has failed because the ID of the UI object is incorrect while the unit test was written.\nInstead of ‘lastName’, the developer has updated it to lastName1.\nAWS CodeBuild Logs How to fix it?\nGo to “AWS CodeCommit’ and navigate to below path:\nawswrkshp-aut-frontend -\u0026gt; test -\u0026gt; applicationcomponents -\u0026gt; testscripts -\u0026gt; unit_tests -\u0026gt; containers and look for the file Register.test.js. This file has unit tests related to ‘registration’.\nTo fix this issue, go to line number 55 and change ‘lastName1’ to ‘lastName’. Refer the screenshot as shown below: Great, you have now debugged and fixed the issue.\nProvide required details such as author name, email address and commit message (change description) and click ‘commit changes’. The Commit Change to the Register.test.js file will trigger the pipeline automatically and this time, it will execute without errors. Refer the screenshot as shown below for ‘succeeded’ status updated against each stage.\nWith the successful execution of the pipeline, you should have a working instance of your application under test, deployed in ECS.\nTo access the application, replace the value of key ‘ApplicationFrontEndURL_DevEnv‘, which you have noted from the secrets (Secrets Manager) section, of the Getting Started section in below URL:\n Application Under Test URL is - http://\u0026lt; ApplicationFrontEndURL_DevEnv\u0026gt;:3000  "
},
{
	"uri": "https://aws-hugo.web.app/46_functional_assurance/3_debug_fix.html",
	"title": "Debug &amp; Fix",
	"tags": [],
	"description": "",
	"content": "DEBUGGING AND RE-EXECUTION Access the reporting dashboard page, refresh to see the failure status and the error message: icon on AWS console to be used to check the error message below:\r\u0026lt; org.openqa.selenium.NoSuchElementException: no such element: Unable to locate element: {\u0026quot;method\u0026quot;:\u0026quot;css selector\u0026quot;,\u0026quot;selector\u0026quot;:\u0026quot;#productsearch\u0026quot;} \u0026gt;\nSuch errors indicate that the automation script is unable to locate the object on the screen as properties of that UI object have seemingly changed since the last build. This is a very common error and calls for script maintenance.\nNavigate to the report to see the error:\n Navigate to Dashboard -\u0026gt; UI Test Report Section -\u0026gt; Click “More Info” -\u0026gt; User will be able to see the report with the error  To fix this issue, navigate to CodeCommit, find the repository “awswrkshp-functional-assurance” and edit the file ShopProductsPage.java awswrkshp-functional-assurance/src/test/java/pages/ShopProductsPage.java\nRefer the screenshot as shown below for details:\nYou will notice at line# 25 as: @FindBy(id = \u0026ldquo;productsearch1\u0026rdquo;) Change the productsearch1 to productsearch\nProvide the required details like author name, email address and commit message (change description) and click ‘commit changes’ . The Commit Change will automatically trigger the pipeline and this time it will be executed successfully. Refer the screenshot as shown below for ‘succeeded’ status updated against each stage.\n"
},
{
	"uri": "https://aws-hugo.web.app/47_experience_assurance/3_debug_fix.html",
	"title": "Debug &amp; Fix",
	"tags": [],
	"description": "",
	"content": "DEBUGGING AND RE-EXECUTION Security test build has failed because the X-Frame-Options was not set in the response headers and this was detected by the ZAP Proxy. This rule is set as “FAIL” in the gen.conf file for ZAP tool.\nTo verify this, go to “Report Dashboard” \u0026ndash;\u0026gt; Go “Experience Assurance” section and Click on the “Rule Report” link under the “Security Test” section. (This will open the security_test_output.txt in browser).\nIf you scroll down to the bottom of the file, you will notice the failure (as shown in the image below)\nFor now, consider this as a “False Positive” and let us fix these issues.\nChange the rule for X-Frame-Options Header Scanner from FAIL to WARN, so that the security test will pass with the warning and the code progresses to the next build step.\nGo to “AWS CodeCommit’ \u0026ndash;\u0026gt; Open the “awswrkshp-tests-security” repository. Locate and open the “gen.conf” file. This will have the set of passive security scan rules to be validated.\nClick on “Edit”.\nChange the rule for X-Frame-Options Header Scanner from FAIL to WARN. Refer the screenshot as shown below for details:\nScroll down to the bottom of the page and provide the required details like author name, email address and commit message (change description) and click ‘commit changes’.\nThe Commit Change to the gen.conf file will trigger the pipeline automatically and this time security testing build will be executed without any errors.\nThe ‘succeeded’ status is now updated for each stage, as shown below:\n"
},
{
	"uri": "https://aws-hugo.web.app/50_conclusion/3_next_step.html",
	"title": "Next Step",
	"tags": [],
	"description": "",
	"content": "Now that you have built your own Testing Pipeline, there are multiple ways in which you can explore the infinite possibilities in Testing that the DevOps world offers.\n Integrate your pipeline with Slack channel to trigger and monitor the execution from Slack interface rather than Cloud9 (or) AWS console Replace (or) append the tooling stack by creating your own automation test with new tools and frameworks Implement Code progression in the pipelines to demonstrate how code base moves form Dev to Production based on the quality gates at every stage Execute your mobile testing on AWS Device Farm Add additional testing types such as integration testing and UAT before releasing the code to production Integrate AI based BOTS for intelligent test execution based on the code committed and possible business impact.  To leverage these learnings in your own work, we encourage you to take small steps towards building a working prototype in your project.\n"
},
{
	"uri": "https://aws-hugo.web.app/45_build_deploy_assurance/3_test_reports_analysis.html",
	"title": "Report &amp; Analysis",
	"tags": [],
	"description": "",
	"content": "TEST REPORT ANALYSIS You can now refresh the reporting dashboard and review the smoke test results for this stage.\nRefer the screenshot as shown below for details:\nUser should be able to see the test summary of the recently executed CodeBuild Project for Smoke Testing. For the detailed report, navigate to detailed report for the corresponding testing type.\nRefer the screenshot as shown below for details:\nicon to be clicked on the right side of each test step, for the corresponding image captured during smoke test execution. This feature helps document the test evidence and supports defect reporting, reproduction and debugging.\r"
},
{
	"uri": "https://aws-hugo.web.app/48_end_to_end_testing_assurance/3_test_reports_analysis.html",
	"title": "Report &amp; Analysis",
	"tags": [],
	"description": "",
	"content": "TEST REPORTS ANALYSIS Reporting dashboard showcases a consolidated view of the statistics applicable for all the types of tests performed as the part of E2E Assurance.\nTo access the dashboard, replace the value of key ‘AppServer_PublicIP‘ which you have noted in output section, of the Getting Started section in the below URL:\nDashboard URL is - http://\u0026lt;AppServer_PublicIP\u0026gt;:3337/report\nClick on the relevant section of the dashboard to view the details of the individual modules covered:\n"
},
{
	"uri": "https://aws-hugo.web.app/50_conclusion/4_final_thoughts.html",
	"title": "Final Thoughts ",
	"tags": [],
	"description": "",
	"content": "Given the nature of this workshop, we have demonstrated just a snapshot of the test execution stage and not the overall testing lifecycle. The test strategy and approach for any system landscape depends on the technology stack, development methodology, tools \u0026amp; framework selections but most importantly testing is driven by the associated business risks and expected customer experience.\nWe recommend you browse through the Cognizant portal for Thought Leadership content especially around whitepapers and blogs written by industry experts and Cognizant automation consultants. We will be happy to collaborate with you, as you embark on your journey to explore the depth and breadth of testing in general and DevOps testing in specific.\nPlease feel free to reach us at AWSWorkshopDevTOps@cognizant.com with any queries / support needed in context of this workshop.\nWarning: Do not forget to clean up resources that were deployed as part of this workshop. Follow the next module to complete the clean-up.\nAdditionally, Practitioners can access Cognizant Thought Leadership on Customer Experience, by referring the detailed whitepaper by our Technology Experts titled - “Automation Assurance Framework to Validate Cloud Readiness”. You will find the link to the whitepaper in the confirmation mailer from Cognizant QE\u0026amp;A, upon successful registration at Cognizant portal.\n "
},
{
	"uri": "https://aws-hugo.web.app/30_pre_build_quality_assurance/4_test_reports_analysis.html",
	"title": "Report &amp; Analysis",
	"tags": [],
	"description": "",
	"content": "TEST REPORTS ANALYSIS To view the CodeQuality and test coverage reports, use SONARQube dashboard for code quality metrics.\nRefer the screenshot as shown below for more details:\nTo view the details of unit test, use the reporting dashboard for all statistics.\nRefer the screenshot as shown below for more details:\n"
},
{
	"uri": "https://aws-hugo.web.app/46_functional_assurance/4_test_reports_analysis.html",
	"title": "Report &amp; Analysis",
	"tags": [],
	"description": "",
	"content": "TEST REPORT ANALYSIS You can find in the S3 buckets, the output artifacts i.e. reports and other files, as follows:\nNote - You can get the name of the S3 Bucket from Secret Manager – ‘Reports’ noted under section ‘Getting Started.’\nYou can now refresh the reporting dashboard and review the test results for this pipeline. Refer the screenshot as shown below:\nSee test summary of the recently executed Functional Assurance pipeline. For detailed report, navigate to ‘More Info’ for the corresponding testing type.\nicon to be clicked on the right side of each test step for the respective image captured during test execution. This feature helps document the test evidence and supports defect reporting, reproduction and debugging.\r"
},
{
	"uri": "https://aws-hugo.web.app/47_experience_assurance/4_test_reports_analysis.html",
	"title": "Report &amp; Analysis",
	"tags": [],
	"description": "",
	"content": "TEST REPORT ANALYSIS Go to the S3 bucket created as part of this demo in the previous modules. Reports and other files can be found in the s3 bucket inside the respective folders, for further analysis and understanding\nYou can now refresh the reporting dashboard and review the test results. Refer the dashboard screenshot as shown below:\nAdditionally, Practitioners can access Cognizant Thought Leadership on Customer Experience, by referring the blog by our Market Expert titled - “From \u0026lsquo;Ensuring Customer Experience’ to \u0026lsquo;Assuring Trust’: Rethinking the Role of QA”. You will find the link to the whitepaper in the Register with Cognizant page - https://www.cognizant.com/application-modernization.\n "
},
{
	"uri": "https://aws-hugo.web.app/48_end_to_end_testing_assurance/4_ai_driven_qa.html",
	"title": "The Accelerator",
	"tags": [],
	"description": "",
	"content": "AI Driven QA An artificial intelligence (AI) driven QA leverages machine learning (ML) and Natural language processing (NLP) algorithms and techniques to build meaningful insights into the product quality. The AI induces this much needed intelligence into the continuous testing pipelines by forecasting possible defects, impacts, gaps, failures and test coverage and help the DevOps teams take informed decisions on run time. No wonder thus that AI is rapidly proving to be the modern day accelerator for testing in DevOps that significantly optimizes the overall testing effort and cycle time.\nWith AI, QA teams can trigger unattended test cycles, where defects are identified and remedial measures are triggered in run time, based on insights gleaned from historical data sets and past events. This way, the AI engine will ensure that only a robust code progresses from one stage to the next, orchestrating quality across the DevOps pipeline.\nAn AI engine assumes the task of checking-off code at quality gates, rendering testing autonomous. By analyzing the results of automated tests, an ML algorithm can pass or fail code progression, creating a fully automated workflow. By orchestrating QA processes with AI, QA teams can:\n  Automate quality gates: As ML algorithms determine if the code is a “go” (or) “no go” based on historical data, QA teams can entrust the AI engine to promote the code (or) shut down features with high probability of causing application outage (or) production defects.\n  Predict root causes: Triaging (or) identifying the root cause of a defect is one of the reasons for delays in releasing new features. With patterns and correlations, ML algorithms can trace defects to root causes, with the AI triggering remedial tests before the code progresses. As AI takes these judgment calls, the margin of error is significantly reduced.\n  Leverage precognitive monitoring: ML algorithms scout for symptoms in coding errors that were previously overlooked. The algorithm can then flag these symptoms, such as a high memory usage, as a potential threat that could result in an outage. As corrective steps, the AI engine can automatically spin-up a parallel process to optimize the server-resource consumption.\n  Additionally, Practitioners can access Cognizant Thought Leadership on Customer Experience, by referring the detailed whitepaper by our Technology Experts titled - “From Continuous to Autonomous Testing with AI”. You will find the link to the whitepaper in the confirmation mailer from Cognizant QE\u0026amp;A, upon successful registration at Cognizant portal.\n "
},
{
	"uri": "https://aws-hugo.web.app/45_build_deploy_assurance/4_the_enablers.html",
	"title": "The Enablers ",
	"tags": [],
	"description": "",
	"content": "In addition to the practices we discussed so far, Service Virtualization (SV) and Test Data Management (TDM) are two enablers that are most critical to the successful implementation of QA in DevOps, since they both result in laying a strong foundation for testing in general and automation in specific. As this workshop focuses on the execution stage, let us discuss their basic concepts and high-level approach.\nService Virtualization Unavailability of environment needed for testing, is the one of the key bottleneck for Continuous Testing in DevOps. This unavailability could be because of many reasons like under development services, shared environments, constraint on access, performance issues (or) due to high cost of usage for third-party interfaces.\nTraditionally development teams solved some of the challenges with stubbing that needs high programming skills and lacks flexibility. Service Virtualization is a modern way to resolve above environment challenges and offers higher flexibility and ease for implementation.\nService Virtualization (SV) is a practice of ‘Capturing and Simulating’ the responses, data and performance of real systems and deploying a Virtual Service to replace them. SV focuses on mimicking the particular interfacing service rather than mimicking an entire application.\nThere are multiple tools available for implementing Service Virtualization, with support for communication (HTTP, MQ, TCP, etc.) and data (SOAP, JSON, SWIFT, etc.) protocols. To make it easy to implement, these tools provide multiple options to create virtual services (from WSDL, with Request/Response [R/R] pair, using recording etc.) to maintain the same (like auto heal, live compare etc.). Once created, Virtual services can be deployed using continuous testing pipeline on demand. This not only reduces environment dependency and associated idle time for testing teams but also increases test coverage with early defect detection. SV brings in much needed agility in testing lifecycle and cuts down the overall release timelines. Its rapidly growing industry adoption is a testimony to the fact that Service Virtualization is acknowledged as a key enabler for QA in DevOps.\nTest Data Provisioning After test environment, Test data has been traditionally the pain area for Quality Assurance. A brilliantly thought-out QA process is bound to fail if the test data it employs is not available (or) is not as per the test specification. Further, the process of provisioning data into the test environments and the data refresh cycles is usually a time consuming, laborious and complex task. If not managed well, test data can be the quintessential bottleneck that can derail continuous testing pipelines.\nQA teams needs accurate and secure data for test execution and need it fast as well. There are essentially two alternatives approaches possible for test data provisioning in test environment viz. sub-setting the production data or creating synthetic data.\nWhile sourcing data from production environments, it is crucial to mask PPI / Sensitive information to avoid data privacy risk and regulation issues. While creating entire data synthetically, can also be a very complex and a laborious process in real time. Thus, the best practice is to have a right blend of both the techniques to achieve agility and security in the data provisioning process.\nAlong with the traditional practices, on-demand data provisioning with self-help portals and data virtualization are modern trends that are growing in industry adoption. DevOps ready enterprise wide test data management solutions are fast gaining their long due respect as the key enablers for efficient and agile testing life cycle.\n"
},
{
	"uri": "https://aws-hugo.web.app/30_pre_build_quality_assurance/5_tikk_talk.html",
	"title": "Tikk Talk",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://aws-hugo.web.app/45_build_deploy_assurance/5_tikk_talk.html",
	"title": "Tikk Talk",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://aws-hugo.web.app/46_functional_assurance/5_tikk_talk.html",
	"title": "Tikk Talk",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://aws-hugo.web.app/47_experience_assurance/5_tikk_talk.html",
	"title": "Tikk Talk",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://aws-hugo.web.app/48_end_to_end_testing_assurance/5_tikk_talk.html",
	"title": "Tikk Talk",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://aws-hugo.web.app/05_introduction/10_devops_puts_testing_at_the_core.html",
	"title": "DevOps puts Testing at the Core",
	"tags": [],
	"description": "",
	"content": "Previously, there was a popular misconception about DevOps, that bringing development and operations teams together would result in greater efficiency, eliminating the very need for testing. However, it was quickly realized that this was not the case. On the contrary, DevOps transformed the role of testing from that of a gatekeeper to a guardian of quality across the lifecycle. This transition eliminates testing silos and instead embeds it in each stage of the DevOps process to deliver much needed quality at speed.\nTesting in DevOps, shifts left towards Development, by helping the Dev team embrace testing to run quality checks during the development process itself, often before they start coding. At the same time, Testing in DevOps also shifts right towards Operations, allowing for incidents in production to be detected faster and before they adversely affect the end-user experience.\n"
},
{
	"uri": "https://aws-hugo.web.app/05_introduction.html",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Introduction "
},
{
	"uri": "https://aws-hugo.web.app/10_prerequisites.html",
	"title": "Prerequisites",
	"tags": [],
	"description": "",
	"content": "Prerequisites "
},
{
	"uri": "https://aws-hugo.web.app/30_pre_build_quality_assurance/10_summary.html",
	"title": "Summary",
	"tags": [],
	"description": "",
	"content": "The cost of fixing an error grows exponentially as it proceeds undetected through the SDLC. Pre-build QA helps in detecting issues early on and preventing the costs of software errors. Especially from a DevOps perspective, it paves way for early testing, bringing in the required agility in the QA cycles and speeding up the time to market.\nWell done! You have successfully fixed the error and executed Pre-Build Quality Assurance Pipeline.\nGo ahead with the next module.\n"
},
{
	"uri": "https://aws-hugo.web.app/20_getting-started/10_permises.html",
	"title": "The Premise",
	"tags": [],
	"description": "",
	"content": "Mythical Mysfits (MM) is an e-commerce giant offering online shopping across a wide array of products. It services global customers via an omni-channel portal.\nProblem Statement - MM intends to speed up their time to market with frequent releases to production.They have implemented a development pipeline, however their testing still follows a traditional waterfall approach, leading to issues such as:\n Increasing efforts spent on testing and re-testing the code changes Defects detected late in testing, costing significant effort, time and resources Siloed automation due to a hybrid tooling landscape Prolonged testing cycles impacting the overall speed of delivery to production Too many production incidents Poor user feedbacks  The Assignment - MM has commissioned Cognizant Consultants to help them modernize their testing practices. Cognizant will enable earlier defect detection and higher-quality deployments by embedding continuous testing in CI/CD pipelines. MM has individual automation suites that Cognizant will orchestrate in the continuous testing pipeline to demonstrate how to deliver Quality at Speed.\nApplication Under Test - Mythical Mysfits E-Shop is a responsive web application used by end-customers for online shopping. The current application is compatible with both desktop and mobile platforms and covers basic shopping workflows.\nKey Features -\n Registration  Login  Product Search  Add to Bag Enter Delivery Details  Checkout  Payment   Application Architecture -\nSolution Overview -\nIn this workshop, we will build and execute the continuous testing pipeline for the E-Shop Application by leveraging AWS services and open source automation tools, as shown below:\n"
},
{
	"uri": "https://aws-hugo.web.app/20_getting-started.html",
	"title": "Getting Started",
	"tags": [],
	"description": "",
	"content": "Getting Started "
},
{
	"uri": "https://aws-hugo.web.app/05_introduction/20_key_tenets_of_testing_in_devops.html",
	"title": "Key Tenets of Testing in DevOps",
	"tags": [],
	"description": "",
	"content": "Testing in DevOps is fundamentally different from traditional legacy testing approaches. For a DevOps program to succeed, testing needs to be:\n Collaborative: Dev, Test and Ops works together as one team to ensure a robust application is built correctly the first time, with quality becoming a shared responsibility across the organization. Automation drives QA and expects enhanced skills and mindset change. Continuous: Testing is executed automatically and continuously throughout the DevOps lifecycle. Automated test scripts are integrated at every stage to engineer quality into the code as it progresses through quality gates. Cognitive: By leveraging artificial intelligence/machine learning, testing can be more proactive than reactive e.g.- predicts defects and required tests based on the actual code changes, thereby optimizing testing efforts and velocity Cloud-Ready: Today cloud brings in agility and scalability to the testing pipelines with on-demand test infrastructures. Going forward, testing for DevOps would become cloud-native, orchestrated on cloud platforms via on-demand tools and resources.  As you start your DevOps journey, Cognizant can help you embrace an automation-first approach for testing and orchestrate quality through the lifecycle.\nBoth, Gartner and Everest recognize us as a leader in Testing. Gartner also ranks Cognizant as a leader in Public Cloud. As the trusted QA partner for over 800 global organizations, we enable our clients accelerate innovation by fostering collaboration between partners and communities.\n"
},
{
	"uri": "https://aws-hugo.web.app/05_introduction/30_whats_in_store_for_practitioners.html",
	"title": "In-store for Practitioners",
	"tags": [],
	"description": "",
	"content": "To introduce you to the world of testing in DevOps, we have planned hands-on exercises and induced real time problems, that we will de-bug and fix together in this workshop.\n Why QA is integral to a successful DevOps implementation How testing in DevOps is different than traditional testing What types and stages of testing are essential for end-to-end quality assurance How to build and execute the continuous testing pipeline What are the various tooling alternatives, enablers and best practices in testing for DevOps How to integrate open source tool-based automation suites in the pipeline How to debug typical issues and fix your continuous testing pipeline  Let us get the jargons out of the way in Software Testing We would like to throw some light on a few common jargons in Software Testing that have been extensively used in this workshop.\nSoftware Testing, as a practice, has evolved significantly over the decades into modern day Quality Engineering and Assurance (QE\u0026amp;A). Today QE\u0026amp;A goes beyond defect detection, it focuses on engineering quality by driving quality across the lifecycle, helping enterprises get first time right. Seen as a critical practice in agile and DevOps, QE\u0026amp;A continues to evolve as clients accelerate their pivot to digital.\nFor such a dynamic practice, almost inevitably, Testing has numerous interpretations and perceptions in the industry. And it reflects nowhere more than the plethora of terms, often used interchangeably, to address Testing depending on the context. While the purists will and should continue to argue the subtle differences and nuances in the jargons, let us agree on some broad understanding of these terms as we will be using them extensively throughout this workshop.\n\u0026ndash; Quality engineering (QE) is the overarching discipline of software engineering concerned with the principles and practice of quality assurance and control. In the software development, it is the about management, development, operation and maintenance of IT systems and enterprise architectures with high quality standards.\n\u0026ndash; Quality assurance (QA) is about focusing on the processes that manages and creates the specific deliverables (product or services) with a desired level of quality across every stage development life cycle.\n\u0026ndash; Testing is an integral part of QA that demonstrates that the product runs the way it is expected and finds the gaps (bugs/defects) when it doesn’t.\n\u0026ndash; Continuous Testing (CT) is the process of executing automated tests as part of the CI/CD pipeline to obtain rapid feedback on the software changes. Continuous Testing is a DevOps aligned practice that enables testing early and testing often with higher levels of automation.\nAt Cognizant, Quality Engineering \u0026amp; Assurance (QE\u0026amp;A) takes an end-to-end, ecosystem-based approach for Continuous Testing in DevOps. We use our intelligent and automated QA practices to engineer quality across the lifecycle drive quality at speed. Our unique Continuous Testing approach assures business agility, superior quality and success in digital for our clients.\n"
},
{
	"uri": "https://aws-hugo.web.app/30_pre_build_quality_assurance.html",
	"title": "Module 1: Pre-Build QA",
	"tags": [],
	"description": "",
	"content": "Pre-Build Quality Assurance "
},
{
	"uri": "https://aws-hugo.web.app/45_build_deploy_assurance/30_summary.html",
	"title": "Summary",
	"tags": [],
	"description": "",
	"content": "As discussed in this module, Post-Build Quality Assurance includes a round of detailed build hardening and build verification testing, before the build is deployed. The build deployment is followed by a quick round Configuration and Smoke testing, to get a rapid feedback on the readiness of that build, for elaborate testing cycles in terms of its availability and accessibility. The idea is to raise quick alarms with the development (or) environment teams in case of any showstoppers for testing (or) to give a green signal to QA teams to proceed with subsequent test executions. This practice potentially saves significant effort waste that testing teams otherwise would have spent on the poor-quality builds and deployments, just to re-execute them again with a new build.\nAdditionally, this is also the stage where test data is provisioned into the test environment. Along with the environment stability, test data is another critical factor for successful test execution with higher pass rate and minimal false negatives.\nAdditionally, Practitioners can access Cognizant Thought Leadership on Automation, by reviewing the detailed whitepaper by our technology experts on “Missing the Mark: 10 Reasons Why Automation Fails Across the Software Dev Lifecycle”.\n Well done! You have successfully fixed the error and executed your Post Build Quality Assurance pipeline.\nYou are good to go ahead with the next module of this workshop.\n"
},
{
	"uri": "https://aws-hugo.web.app/46_functional_assurance/30_summary.html",
	"title": "Summary",
	"tags": [],
	"description": "",
	"content": "Testing in DevOps essentially means testing early and testing often. Thus, it is implicit that functional automation must go beyond the traditional UI based tests, to leverage other architectural components such as data and services. This speeds up test execution and helps with shift left as now you can validate these components as soon as they are developed, rather than waiting for the Development team to deliver a working UI.\nFor this workshop, we have considered only select tests, in practice however, functional assurance consists of a wide range of testing types and stages, here is an indicative list for your reference:\nWell done! You have successfully fixed the error and executed your functional assurance pipeline.\nYou are good to go with the next module of this workshop.\n"
},
{
	"uri": "https://aws-hugo.web.app/47_experience_assurance/30_summary.html",
	"title": "Summary",
	"tags": [],
	"description": "",
	"content": "In DevOps, it is crucial to shift non-functional testing to left to provide faster feedbacks on potential performance bottlenecks, security vulnerabilities and accessibility issues. The pipeline moves through different stages of testing and generates reports on non-functional defects, addresses test incidents and confirms the overall state of experience delivered by the application.\nFor this workshop, we have only considered selective non-functional checks. However, in practice, assuring experience consists of a large gamut of non-functional tests and practices.\nRefer the diagram shown below for the types of tests for Experience Assurance:\nAdditionally, Practitioners can access Cognizant Thought Leadership on Security Assurance, by reading the blog by our subject matter expert on “Five Steps to Ensure Continuous Security with an Agile Approach”.\n Well done! You have successfully fixed the error and executed the experience assurance pipeline.\nProceed ahead to the final module of this workshop.\n"
},
{
	"uri": "https://aws-hugo.web.app/48_end_to_end_testing_assurance/30_summary.html",
	"title": "Summary",
	"tags": [],
	"description": "",
	"content": "In this module, we have witnessed the end-to-end successful test execution for a happy path scenario. The idea is to demonstrate how the continuous pipelines will be executed in real time progressing the code through various quality gates and ensuring that the every aspect of a code change is tested and confirmed before it is certified for pre-production environments.\nAs discussed at the start, we have now seen how Testing in DevOps should be continuous in execution, collaborative by nature, cognitive with its decision-making and cloud ready in its architecture. In this module, we have seen a brief demonstration of how it all comes together in real time.\nWell done! You have successfully executed the end-to-end testing pipeline.\nLet us recap our leanings and discuss the next steps in the next section.\n"
},
{
	"uri": "https://aws-hugo.web.app/20_getting-started/30_workshop_structure_rules.html",
	"title": "The Structure",
	"tags": [],
	"description": "",
	"content": "  Scope: For this workshop, we will focus on the execution stage of the testing pipeline and not the complete testing life cycle.\n  Modular Structure: This workshop constitutes of five modules that explain a continuous testing pipeline in a chronological sequence. Each module provides an overview, relevant concepts and practices, before getting into the pipeline execution. In order to get the best out this workshop, we recommend you to follow the sequence and build your pipeline in progression.\n  Solve and Learn: We have induced few defects in the application code and test assets, so that you can debug and fix them to gain a more practical insight into this workshop.\n  Possibilities Infinitum: There is no one right way to test an application. For this workshop, we have made a few broad assumptions for our testing approach, pipeline orchestration, tools and frameworks.\n  Meet Tikk!: The over-enthusiastic, effervescent and self-confessed testing geek. Tikk is your assistant for this workshop. In the section - ‘Tikk Talk’, Tikk shares interesting info like - alternative approaches, practitioner tips, best practices, industry trends and trivia.\n  "
},
{
	"uri": "https://aws-hugo.web.app/20_getting-started/40_getting_your_environment_ready.html",
	"title": "The Environment",
	"tags": [],
	"description": "",
	"content": "Creating Your Environment For this workshop, you will need to setup and configure your environment as below:\n Spin AWS Cloud9, leveraging CloudFormation to create source repositories and foundation infrastructure Run a few custom scripts.  This will build the required infrastructure and pre-configured pipelines required for this workshop so that you can focus on the learning without worrying about the peripherals.\nDeploy \u0026amp; Launch AWS Cloud9 There are several ways you can provision AWS Cloud9, however, for this workshop, we will use AWS Management Console  to create our environment.\nGo to Cloud9 service from AWS Management Console and -\n Click on Create Environment. Enter Name and Description and Click on Next Steps. In the Configure Settings section, leave the default values as it is and click on Next Steps. Review and click on Create environment.  INFO: The creation of Cloud9 environment can take 1-2 minutes, depending on the region you are operating from.\nYou should see the screen as shown below:\nYour Cloud9 environment is ready.\nCreate the source repositories Now, we need seven repositories for the essential code base required for this workshop.\nTo create these repositories, run the following commands in Cloud9’s terminal:\n\raws cloudformation create-stack --stack-name CreateRepositories --template-url https://aws-wrkshp-artifacts.s3-eu-west-1.amazonaws.com/awsworkshop_infrastructure_artefacts/awsworkshop_create_repositories.json This step takes approximately 30 seconds, after which, you should see the message as shown below:\nTo verify the repositories, go to CodeCommit in AWS Console where they should reflect as shown below:\nNOTE – At this point, all the repositories are blank. In the next step, we are going to push the code to these repositories. Refer screenshot as shown below:\nPushing the code to source repositories Run the following 3 commands in Cloud9’s terminal in sequence:\nwget https://aws-wrkshp-artifacts.s3-eu-west-1.amazonaws.com/awsworkshop_infrastructure_artefacts/pull_push_repos.sh INFO: This complete step takes approximately 1 minute and if successful, you should see the following relevant messages for each command as shown below:\nchmod +x ./pull_push_repos.sh ./pull_push_repos.sh At this point, you should have all the necessary code repositories with the required code base for this workshop. You can refer the README.md file of each repository to get more information on what the repository contains.\nSetup Foundation Infrastructure Now, you are ready to deploy the infrastructure that will be leveraged during this workshop by creating and setting up services such as VPC, Subnets, Elastic IPs, Amazon EC2, Security groups, S3 Buckets, secrets in AWS Secrets Manager and Amazon ECR services.\nCopy and paste the following command into Cloud9’s terminal to create a foundation stack named -‘CreateFoundationStack’.\naws cloudformation create-stack --stack-name CreateFoundationStack --template-url https://aws-wrkshp-artifacts.s3-eu-west-1.amazonaws.com/awsworkshop_infrastructure_artefacts/awsworkshop_create_foundation_stack.json --capabilities CAPABILITY_NAMED_IAM Go to the CloudFormation console and check the status of your foundation stack creation. It should be “CREATE_IN_PROGRESS”\r.\nINFO: This step takes approximately 4 minutes and if successful, you can see the status of STACK as “CREATE_COMPLETE”\r.\nPlease navigate to below path in AWS Secrets Manager and you can see the details of the infrastructure created. Refer screenshot as shown below:\nAWS Secrets Manager -\u0026gt; wrkshpSecrets -\u0026gt; Retrieve secret value\nPlease verify other services as well e.g. S3 Bucket, Secrets in AWS Secrets Manager. All the necessary details are added in AWS Secrets Manager as Secrets, so that these values can be utilized throughout the various components that you will build as the part of this workshop.\nAs a part of this setup, you have also installed SONARQube and a customized reporting dashboard. Both are required to check the status and progress of your testing.\nWe recommend you keep these open in your browser throughout the workshop:  Access SONARQube dashboard: http://\u0026lt;AppServer_PublicIP\u0026gt;:9000 Access Reporting dashboard: http://\u0026lt;AppServer_PublicIP \u0026gt;:3337  Replace the actual IPs from your Secrets Manager in these links (*) to access the dashboards\nWell done! Your environment is now ready to go.\nLet’s kick start the workshop and delve deeper into the what, why and how of ‘Test Automation in DevOps’.\n"
},
{
	"uri": "https://aws-hugo.web.app/45_build_deploy_assurance.html",
	"title": "Module 2: Post-Build QA",
	"tags": [],
	"description": "",
	"content": "Post-Build Quality Assurance "
},
{
	"uri": "https://aws-hugo.web.app/46_functional_assurance.html",
	"title": "Module 3: Functional Assurance ",
	"tags": [],
	"description": "",
	"content": "Functional Assurance "
},
{
	"uri": "https://aws-hugo.web.app/47_experience_assurance.html",
	"title": "Module 4: Experience Assurance",
	"tags": [],
	"description": "",
	"content": "Experience Assurance "
},
{
	"uri": "https://aws-hugo.web.app/48_end_to_end_testing_assurance.html",
	"title": "Module 5: End to End Execution  ",
	"tags": [],
	"description": "",
	"content": "End to End Execution "
},
{
	"uri": "https://aws-hugo.web.app/50_conclusion.html",
	"title": "Conclusion",
	"tags": [],
	"description": "",
	"content": "Conclusion "
},
{
	"uri": "https://aws-hugo.web.app/60_clean_up.html",
	"title": "Clean-up",
	"tags": [],
	"description": "",
	"content": "Cleanup "
},
{
	"uri": "https://aws-hugo.web.app/categories.html",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://aws-hugo.web.app/tags.html",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]